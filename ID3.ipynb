{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr7rYfZz4ctxFXnXURy2Vi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganashreecs22/ml_lab/blob/main/ID3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER7cX3Bm2KWO",
        "outputId": "eaae5aa2-a82a-48ff-c3ad-00e8dedcf353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "{'Outlook': {'Sunny': {'Humidity': {'High': 'No', 'Normal': 'Yes'}}, 'Overcast': 'Yes', 'Rain': {'Wind': {'Weak': 'Yes', 'Strong': 'No'}}}}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd  # for manipulating the csv data\n",
        "import numpy as np    # for mathematical calculation\n",
        "\n",
        "# Load dataset\n",
        "train_data_m = pd.read_csv(\"/content/PlayTennis.csv\")\n",
        "\n",
        "# Function to calculate total entropy of the dataset\n",
        "def calc_total_entropy(train_data, label, class_list):\n",
        "    total_row = train_data.shape[0]\n",
        "    total_entr = 0\n",
        "    for c in class_list:\n",
        "        total_class_count = train_data[train_data[label] == c].shape[0]\n",
        "        if total_class_count != 0:\n",
        "            probability = total_class_count / total_row\n",
        "            total_entr -= probability * np.log2(probability)\n",
        "    return total_entr\n",
        "\n",
        "# Function to calculate entropy for a subset of the data\n",
        "def calc_entropy(feature_value_data, label, class_list):\n",
        "    class_count = feature_value_data.shape[0]\n",
        "    entropy = 0\n",
        "    for c in class_list:\n",
        "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0]\n",
        "        if label_class_count != 0:\n",
        "            probability_class = label_class_count / class_count\n",
        "            entropy -= probability_class * np.log2(probability_class)\n",
        "    return entropy\n",
        "\n",
        "# Function to calculate information gain for a feature\n",
        "def calc_info_gain(feature_name, train_data, label, class_list):\n",
        "    feature_value_list = train_data[feature_name].unique()\n",
        "    total_row = train_data.shape[0]\n",
        "    feature_info = 0.0\n",
        "    for feature_value in feature_value_list:\n",
        "        feature_value_data = train_data[train_data[feature_name] == feature_value]\n",
        "        feature_value_count = feature_value_data.shape[0]\n",
        "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list)\n",
        "        feature_info += (feature_value_count / total_row) * feature_value_entropy\n",
        "    return calc_total_entropy(train_data, label, class_list) - feature_info\n",
        "\n",
        "# Find the most informative feature\n",
        "def find_most_informative_feature(train_data, label, class_list):\n",
        "    feature_list = train_data.columns.drop(label)\n",
        "    max_info_gain = -1\n",
        "    max_info_feature = None\n",
        "    for feature in feature_list:\n",
        "        feature_info_gain = calc_info_gain(feature, train_data, label, class_list)\n",
        "        if max_info_gain < feature_info_gain:\n",
        "            max_info_gain = feature_info_gain\n",
        "            max_info_feature = feature\n",
        "    return max_info_feature\n",
        "\n",
        "# Generate subtree for a feature\n",
        "def generate_sub_tree(feature_name, train_data, label, class_list):\n",
        "    feature_value_count_dict = train_data[feature_name].value_counts(sort=False)\n",
        "    tree = {}\n",
        "    rows_to_remove = []\n",
        "\n",
        "    for feature_value, count in feature_value_count_dict.items():\n",
        "        feature_value_data = train_data[train_data[feature_name] == feature_value]\n",
        "        assigned_to_node = False\n",
        "        for c in class_list:\n",
        "            class_count = feature_value_data[feature_value_data[label] == c].shape[0]\n",
        "            if class_count == count:\n",
        "                tree[feature_value] = c\n",
        "                rows_to_remove.append(feature_value_data.index)\n",
        "                assigned_to_node = True\n",
        "                break\n",
        "        if not assigned_to_node:\n",
        "            tree[feature_value] = \"?\"\n",
        "    train_data = train_data.drop(index=np.concatenate(rows_to_remove)) if rows_to_remove else train_data\n",
        "    return tree, train_data\n",
        "\n",
        "# Recursive tree-building function\n",
        "def make_tree(root, prev_feature_value, train_data, label, class_list):\n",
        "    if train_data.shape[0] != 0:\n",
        "        max_info_feature = find_most_informative_feature(train_data, label, class_list)\n",
        "        if max_info_feature is None:\n",
        "            return\n",
        "        tree, updated_train_data = generate_sub_tree(max_info_feature, train_data, label, class_list)\n",
        "        next_root = None\n",
        "        if prev_feature_value is not None:\n",
        "            root[prev_feature_value] = {max_info_feature: tree}\n",
        "            next_root = root[prev_feature_value][max_info_feature]\n",
        "        else:\n",
        "            root[max_info_feature] = tree\n",
        "            next_root = root[max_info_feature]\n",
        "        for node, branch in list(next_root.items()):\n",
        "            if branch == \"?\":\n",
        "                feature_value_data = updated_train_data[updated_train_data[max_info_feature] == node]\n",
        "                make_tree(next_root, node, feature_value_data, label, class_list)\n",
        "\n",
        "# ID3 entry point\n",
        "def id3(train_data_m, label):\n",
        "    train_data = train_data_m.copy()\n",
        "    tree = {}\n",
        "    class_list = train_data[label].unique()\n",
        "    make_tree(tree, None, train_data, label, class_list)\n",
        "    return tree\n",
        "\n",
        "# Prediction function for a single instance\n",
        "def predict(tree, instance):\n",
        "    if not isinstance(tree, dict):\n",
        "        return tree\n",
        "    root_node = next(iter(tree))\n",
        "    feature_value = instance[root_node]\n",
        "    if feature_value in tree[root_node]:\n",
        "        return predict(tree[root_node][feature_value], instance)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Evaluate the decision tree\n",
        "def evaluate(tree, test_data_m, label):\n",
        "    correct_predict = 0\n",
        "    wrong_predict = 0\n",
        "    for index, row in test_data_m.iterrows():\n",
        "        result = predict(tree, row)\n",
        "        actual = row[label]\n",
        "        if result == actual:\n",
        "            correct_predict += 1\n",
        "        else:\n",
        "            wrong_predict += 1\n",
        "    total = correct_predict + wrong_predict\n",
        "    accuracy = correct_predict / total if total != 0 else 0\n",
        "    return accuracy\n",
        "\n",
        "# Build and evaluate tree\n",
        "tree = id3(train_data_m, 'Play Tennis')\n",
        "test_data_m = pd.read_csv(\"/content/PlayTennis.csv\")\n",
        "accuracy = evaluate(tree, test_data_m, 'Play Tennis')\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(tree)"
      ]
    }
  ]
}